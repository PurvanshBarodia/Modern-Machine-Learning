{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurvanshBarodia/Modern-Machine-Learning/blob/main/Module%209/FMML20210266__Module_9_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF8nIY5yEw3Z"
      },
      "source": [
        "# Module 9: CNN Project\n",
        "\n",
        "## Module coordinator: Ekta Gavas\n",
        "\n",
        "In this project, you will understand how you can perform emotion recognition using CNNs in a step-by-step manner. To make your task easier, we provide you the starter code for the project. It is expected that you should try to understand the project statement properly and perform the tasks in sequence. We will be using Pytorch framework for the implementation. You need to fill in the missing code parts to achieve a particular task. At the end, you will have a basic implementation ready for an emotion detection application.\n",
        "\n",
        "Basic steps involved in Emotion Recognition:\n",
        "- Face detection\n",
        "- Building classifier\n",
        "- Classifying emotions\n",
        "\n",
        "We will use a popular FER2013 dataset for this project. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpBbqZ39FF_Y"
      },
      "source": [
        "## Task 1: Explore the dataset\n",
        "The dataset contains 48 x 48 grayscale facial images of faces.The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXy7bFuIFPA_"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh_RSwSCEnrZ"
      },
      "outputs": [],
      "source": [
        "# We have imported the necessary packages here. Feel free to import anything more you need!\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import dlib\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9BUAlmDFeEJ"
      },
      "source": [
        "### Download and load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaPP5dHSFWgM"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1YrNrok2Z1udWWIpejXIdLk7duUq87s0N\n",
        "!unzip fer2013.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LOSUCeZFglQ"
      },
      "outputs": [],
      "source": [
        "# Load the dataset csv using pandas package. It displays the data in tabular form\n",
        "emotion_data = pd.read_csv('./fer2013.csv')\n",
        "print(emotion_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "petzLP_HFjNk"
      },
      "outputs": [],
      "source": [
        "# Class dictionary for dataset\n",
        "classes = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyWdEqz3FpCl"
      },
      "source": [
        "### Visualize a few images from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnuUwMwaFoWo"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12,4))\n",
        "for i in range(10):\n",
        "  ax = plt.subplot(2,5,i+1)\n",
        "  # This is how we access ith row in 'pixels' column in the dataset table\n",
        "  img = emotion_data.iloc[i]['pixels'].split(' ') # Converting into array of ints \n",
        "  img = np.array(img).astype(int)\n",
        "\n",
        "  # Labels for our dataset\n",
        "  label = int(emotion_data.iloc[i]['emotion'])\n",
        "  ax.imshow(img.reshape((48,48)), cmap='gray')\n",
        "  ax.set_title(classes[label])\n",
        "  ax.set_axis_off()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOYEnyhqFquh"
      },
      "outputs": [],
      "source": [
        "names, counts = np.unique(emotion_data['Usage'].to_numpy(), return_counts=True)\n",
        "print('Number of samples in {} = {}'.format(names[0], counts[0])) #testset\n",
        "print('Number of samples in {} = {}'.format(names[1], counts[1])) #valset\n",
        "print('Number of samples in {} = {}'.format(names[2], counts[2])) #trainset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exip5hjXF9uu"
      },
      "source": [
        "### Distribution of class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fu3LIjCFzva"
      },
      "outputs": [],
      "source": [
        "# Plot bar chart showing number of samples per class in the train set\n",
        "temp_train = emotion_data.loc[emotion_data['Usage'] == 'Training']\n",
        "df_temp_train = temp_train.sort_values(by = \"emotion\", inplace = False)\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"Count of each Emotion in Train Data\", fontsize = 20)\n",
        "sns.countplot(x = \"emotion\", data = df_temp_train)\n",
        "plt.grid()\n",
        "for i in ax.patches:\n",
        "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
        "plt.xlabel(\"Classes\"+ str(classes))\n",
        "plt.ylabel(\"Count\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.xticks(rotation = 40)\n",
        "plt.show()\n",
        "\n",
        "### Task: Similarly, write the code below to plot the charts for remaining two sets also.\n",
        "#For Validation Data\n",
        "temp_val = emotion_data.loc[emotion_data['Usage'] == 'PublicTest']\n",
        "df_temp_val = temp_val.sort_values(by = \"emotion\", inplace = False)\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"Count of each Emotion in Validation Data\", fontsize = 20)\n",
        "sns.countplot(x = \"emotion\", data = df_temp_val)\n",
        "plt.grid()\n",
        "for i in ax.patches:\n",
        "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
        "plt.xlabel(\"Classes\"+ str(classes))\n",
        "plt.ylabel(\"Count\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.xticks(rotation = 40)\n",
        "plt.show()\n",
        "\n",
        "# For Test Data\n",
        "temp_test = emotion_data.loc[emotion_data['Usage'] == 'PrivateTest']\n",
        "df_temp_test = temp_test.sort_values(by = \"emotion\", inplace = False)\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"Count of each Emotion in Test Data\", fontsize = 20)\n",
        "sns.countplot(x = \"emotion\", data = df_temp_test)\n",
        "plt.grid()\n",
        "for i in ax.patches:\n",
        "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
        "plt.xlabel(\"Classes\"+ str(classes))\n",
        "plt.ylabel(\"Count\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.xticks(rotation = 40)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgyJVkVeGJiY"
      },
      "source": [
        "Note the imbalance in the data through above graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGzXGpFgHcED"
      },
      "source": [
        "Face detection: Many applications involving facial images as input data require face detection in the pipeline at this step. Here, we localise the face in the given image removing the irrelevant parts, making the face centered and occupying most of the part in the image. As mentioned earlier, our dataset already has more or less centered faces, so we will skip this step for now but when using some other dataset or using your own images (eg. from webcam) as you will do later, you can do this step to get a proper cropped face from the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqBdliUNhiS"
      },
      "source": [
        "## Task 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QmcaX7yNsMf"
      },
      "source": [
        "### Creating train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eBsC7i2-NTI",
        "outputId": "dffefd9d-7961-4626-c5fe-9b7c07245bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape:  (28709, 2304) (28709,)\n",
            "Validation set shape:  (3589, 2304) (3589,)\n",
            "Testing set shape:  (3589, 2304) (3589,)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = [], []\n",
        "X_val, y_val = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for index, row in emotion_data.iterrows():\n",
        "  k = row['pixels'].split(\" \")\n",
        "\n",
        "  if row['Usage'] == 'Training':\n",
        "    X_train.append(np.array(k))\n",
        "    y_train.append(row['emotion'])\n",
        "\n",
        "  # Similarly write the conditions for test and val splits here\n",
        "  ###### YOUR CODE HERE  ######\n",
        "  elif row['Usage'] == 'PublicTest':\n",
        "    X_val.append(np.array(k))\n",
        "    y_val.append(row['emotion'])\n",
        "\n",
        "  else:\n",
        "    X_test.append(np.array(k))\n",
        "    y_test.append(row['emotion'])\n",
        "\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_val, y_val = np.array(X_val), np.array(y_val)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "print('Training set shape: ', X_train.shape, y_train.shape)\n",
        "print('Validation set shape: ', X_val.shape, y_val.shape)\n",
        "print('Testing set shape: ', X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4pvWe82a_KIO"
      },
      "outputs": [],
      "source": [
        "# To get data between 0 and 1\n",
        "X_train = X_train.astype(float) / 255.\n",
        "X_test = X_test.astype(float) / 255.\n",
        "X_val = X_val.astype(float) / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZEgGchZlL6Z",
        "outputId": "cd185c8f-0351-4719-9ccb-b8a8080af58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28709, 2304)\n"
          ]
        }
      ],
      "source": [
        "print(    X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_A4SIWRYvVd"
      },
      "source": [
        "We will define a dataset wrapper over Pytorch Dataset class which takes in the numpy arrays we created and returns a sample with required preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xkU6ZNlIl_uw"
      },
      "outputs": [],
      "source": [
        "class Fer2013Dataset(Dataset):\n",
        "  def __init__(self, x, y, transforms=None):\n",
        "    self.x = x.reshape((-1, 48, 48))\n",
        "    self.y = y\n",
        "    self.transforms= transforms\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, y = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transforms is not None:\n",
        "        img = self.transforms(img)\n",
        "    return img, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "cfyIAW5tYZXf"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Create tensor dataset from above tensors\n",
        "train_dataset = Fer2013Dataset(X_train, y_train, transforms=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "val_dataset = Fer2013Dataset(X_val, y_val, transforms=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "test_dataset = Fer2013Dataset(X_test, y_test, transforms=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVeKhcxOaOi-"
      },
      "source": [
        "## Task 3: Building a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0-fjjr6UZ1sc"
      },
      "outputs": [],
      "source": [
        "# Define your CNN architecture here\n",
        "# To start with, let's say you can create a model with 4 relu-activated convs, \n",
        "# each followed by a pooling layer. Then, you can add 2-3 fully connected layers\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        #### YOUR CODE HERE  ####\n",
        "        self.conv1 = nn.Conv2d(1, 48, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(48,41 , 3)\n",
        "        self.conv3 = nn.Conv2d(41,24, 3)\n",
        "        self.conv4 = nn.Conv2d(24, 12, 3)\n",
        "        self.fc1 = nn.Linear(4100, 6550)\n",
        "        self.fc2 = nn.Linear(6550, 500)\n",
        "        # output layer 10 classes\n",
        "        self.fc3 = nn.Linear(500, 7)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        #### YOUR CODE HERE  ####\n",
        "        x = x.float()\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # flatten all dimensions except batch\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2oKndcbVKa",
        "outputId": "7e78c59f-9f2d-40fa-9af4-5dcc7061c170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(48, 41, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(41, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=4100, out_features=6550, bias=True)\n",
            "  (fc2): Linear(in_features=6550, out_features=500, bias=True)\n",
            "  (fc3): Linear(in_features=500, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Device (CPU/GPU)\n",
        "device = 'cpu' #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the CNN\n",
        "model = Net().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JffKONlJKQXr"
      },
      "source": [
        "### Training/Testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "S6BE_5aPF_eF"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_func, optimizer, num_epochs):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the modelyy\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "      # clear gradients for this training step   \n",
        "      optimizer.zero_grad()           \n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients             \n",
        "      optimizer.step()                \n",
        "      \n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      # Average loss and acc values \n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "w2BCd3JOJHnM"
      },
      "outputs": [],
      "source": [
        "def test_model(model, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # Calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # The class with the highest value is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network: %d %%' % (\n",
        "      100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcBGf4oZdRYD"
      },
      "source": [
        "## Task 4: Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrXHHTlfDNj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gFK55ULTm_6u"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKRqaFn6dU3t"
      },
      "outputs": [],
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer with learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)   # Pick an optimizer you think is suitable\n",
        "\n",
        "history = train(model, train_loader, criterion, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG1wb_bFKvv3"
      },
      "outputs": [],
      "source": [
        "# You can fine-tune your model looking at below plots\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(history[0])+1),history[0])\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(history[1])+1),history[1])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIc4E7dDd-RJ"
      },
      "source": [
        "### Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofh6NYJe_AfQ"
      },
      "outputs": [],
      "source": [
        "# Visualize top K predictions\n",
        "def visualize_prediction(image, model, k=3):\n",
        "  model.eval()\n",
        "\n",
        "  preds = model(image.unsqueeze(1).float())\n",
        "\n",
        "  topk = torch.topk(preds, k, dim=1)\n",
        "  topk = topk.indices.numpy()\n",
        "  print('Top {} Predictions'.format(k))\n",
        "  for i in range(3):\n",
        "    print('{}) {}'.format(i+1, classes[topk[0][i]]))\n",
        "\n",
        "  plt.imshow(image[0].numpy(), cmap='gray')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HexADTCBiFU"
      },
      "outputs": [],
      "source": [
        "image, label = test_dataset[0]\n",
        "visualize_prediction(image, model)\n",
        "print('\\nTrue label: ', classes[int(label)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NN8ebRBeZVL"
      },
      "outputs": [],
      "source": [
        "# Print accuracy on test data\n",
        "predicted_labels = test_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKol6aILkto"
      },
      "source": [
        "Bonus: \n",
        "If you feel confident enough, you can try replacing your CNN model with a pretrained model like resnet or vgg and check the performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FMML20210266_ Module 9_ Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}